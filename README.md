# Multi-Agent Simulated Environments Generated by a Transformer-Based Generative Model
![generated_pong_2agnts](https://github.com/Masao-Taketani/multi-agent-env-generator/assets/37681936/59c46831-87fd-49e3-88cb-05f2d1ff7836)
![generated_pong_4agnts](https://github.com/Masao-Taketani/multi-agent-env-generator/assets/37681936/d95d834f-abfc-438e-add5-d4e108be3dc9)
![generated_boxing](https://github.com/Masao-Taketani/multi-agent-env-generator/assets/37681936/6b92fde8-f061-453b-b5fc-debc3a569e1c)
![generated_gtav](https://github.com/Masao-Taketani/multi-agent-env-generator/assets/37681936/d2ce14b8-3897-4db3-8179-1a5c02c84ca0)
![generated_carla](https://github.com/Masao-Taketani/multi-agent-env-generator/assets/37681936/9042941c-d4b1-413b-92b0-51bfa0d4b784)
<br>
[Paper Link](https://github.com/Masao-Taketani/multi-agent-env-generator/blob/main/paper/Master_Thesis.pdf)
<br>
[Link of trained weights](https://drive.google.com/drive/folders/1FEXgXS-BF_1NyhY_RlrjUqFcUJICIYRy?usp=sharing)

> [!NOTE]
> Please also refer to `scripts` directory as to 1st and 2nd training phases and encoding images after 1st training phase. Hyperparameters we applied for each dataset are also listed there.

> [!TIP]
> We used a single GPU having 48GB GPU memory for 2nd training phase. If your machine has smaller GPU memory size, reduce the batch size.

## Build the Environment
```
docker build -t [Docker image name] .
docker run --rm -it --ipc=host --gpus '"device=[device id(s)]"' -v $(pwd):/work [Docker image name]:latest
```

## Supported Datasets
Choose a dataset name among `boxing`, `pong`, `carla` or `gtav`.<br>
As for an image size, specify `64x64` for `boxing`, `pong` or `carla` and `48x80` for `gtav`.

## Data Creation
```
python data/multi_thread_processing.py --dataset [dataset name] --num_eps 1500 --data_dir datasets --num_threads [number of threads] --num_agents [number of agents]
```
Then create a file to split the dataset into train, validation, and test datasets.<br>
```
python data/data_split.py --datapath [dataset path]
```

## Encoder and Decoder Training
```
python enc_dec_training.py --log_dir [log path] --use_perceptual_loss --batch [batch size] --data_path [dataset path] --dataset [dataset name]
```

## Preparation for Transition Learner Training by Encoding Images into Latent Vectors
```
python latent_encoder.py --ckpt [checkpoint path] --results_path [output path for encoded dataset] --data_path [dataset path] --dataset [dataset name] --img_size [image size(heightxweight)]
```
Use `--visualize 1` and specify `--vis_bs [batch size for visualization]` to check the images after encoding and decoding are applied for debugging purposes. 

## Transition Learner Training
As for `action_space` argument, specify `4` for `pong`, `6` for `boxing`, `2` for `carla`, and `3` for `gtav`.<br> 
To train Transition Learner, there are two ways provided.<br>
[1] Train with auto-regressive.
```
python trans_learner_training_ar.py --batch_size [batch size] --data_dir [dataset directory path] --num_workers [number of data processing workers] --max_seq_len [maximum sequential length for each visual and actions]
```
[2] Train with GAN.
```
python trans_learner_training_gan.py --batch_size [batch size] --data_dir [dataset directory path] --num_workers [number of data processing workers] --max_seq_len [maximum sequential length for each emb of visual frames and actions] --num_transenclayer [number of transformer layers] --attn_mask_type [attention mask type] --dataset [dataset name] --action_space [number of action space]
```

## Simulator Execution
`sudo` is required to run `keyboard` module. The followings are command descriptions for all the environments supported to run on this repo.
- [GTAâ…¤]<br>
Left: a, Right: d<br>
- [Pong (2 agents)]<br>
1st agent: Fire: w, Left: a, Right: d<br>
2nd agent: Fire: i, Left: j, Right: l<br>
- [Boxing]<br>
1st agent: Fire: e, Left: a, Right: d, Up: w, Down: s<br>
2nd agent: Fire: u, Left: j, Right: l, Up: i, Down: k<br>

> [!TIP]
> As for `pong` environment, the transitions of the environment is rather slow. In case you feel the same, use `--fps 60` for more challenging transition speed. 

```
sudo python3 simulator.py --encdec_ckpt [encoder decoder checkpoint path] --trans_ckpt [transition learner checkpoint path] --init_img_path [initial image path]
```

## References
- [Sentdex/GANTheftAuto](https://github.com/Sentdex/GANTheftAuto)
- [nv-tlabs/DriveGAN_code](https://github.com/nv-tlabs/DriveGAN_code)
- [alexpashevich/E.T.](https://github.com/alexpashevich/E.T.)

## License
- This codebase is based on [nv-tlabs/DriveGAN_code](https://github.com/nv-tlabs/DriveGAN_code) repository, which has [Nvidia Source Code License](https://github.com/Masao-Taketani/multi-agent-env-generator/blob/main/LICENSE-NVIDIA).
- Code for Lpips is imported from https://github.com/richzhang/PerceptualSimilarity ([License](https://github.com/Masao-Taketani/multi-agent-env-generator/blob/main/LICENSE-LPIPS)).
